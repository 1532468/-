{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ad41718-e2f2-47da-a40f-e8d2d8d34fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Navy\\anaconda3\\envs\\BCODE\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: \n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "usage: ipykernel_launcher.py [-h]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\Navy\\AppData\\Roaming\\jupyter\\runtime\\kernel-5e4fd82f-1805-49b8-b979-8aed9ca3a5f4.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Navy\\anaconda3\\envs\\BCODE\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3465: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import torch\n",
    "from sklearn.metrics import precision_recall_fscore_support as prfs\n",
    "from utils.parser import get_parser_with_args\n",
    "from utils.helpers import (get_loaders, get_criterion,\n",
    "                           load_model, initialize_metrics, get_mean_metrics,\n",
    "                           set_metrics)\n",
    "import os\n",
    "import logging\n",
    "import json\n",
    "from tensorboardX import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Initialize Parser and define arguments\n",
    "\"\"\"\n",
    "parser, metadata = get_parser_with_args()\n",
    "opt = parser.parse_args()\n",
    "\n",
    "\"\"\"\n",
    "Initialize experiments log\n",
    "\"\"\"\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "writer = SummaryWriter(opt.log_dir + f'/{datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")}/')\n",
    "\n",
    "\"\"\"\n",
    "Set up environment: define paths, download data, and set device\n",
    "\"\"\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "dev = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "logging.info('GPU AVAILABLE? ' + str(torch.cuda.is_available()))\n",
    "\n",
    "def seed_torch(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # torch.cuda.manual_seed_all(seed) # if you are using multi-GPU.\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_torch(seed=777)\n",
    "\n",
    "\n",
    "train_loader, val_loader = get_loaders(opt)\n",
    "\n",
    "\"\"\"\n",
    "Load Model then define other aspects of the model\n",
    "\"\"\"\n",
    "logging.info('LOADING Model')\n",
    "model = load_model(opt, dev)\n",
    "\n",
    "criterion = get_criterion(opt)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=opt.learning_rate) # Be careful when you adjust learning rate, you can refer to the linear scaling rule\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=8, gamma=0.5)\n",
    "\n",
    "\"\"\"\n",
    " Set starting values\n",
    "\"\"\"\n",
    "\n",
    "if __name__ == '__main__' :\n",
    "    freeze_support()\n",
    "    best_metrics = {'cd_f1scores': -1, 'cd_recalls': -1, 'cd_precisions': -1}\n",
    "    logging.info('STARTING training')\n",
    "    total_step = -1\n",
    "\n",
    "    for epoch in range(opt.epochs):\n",
    "        train_metrics = initialize_metrics()\n",
    "        val_metrics = initialize_metrics()\n",
    "\n",
    "        \"\"\"\n",
    "        Begin Training\n",
    "        \"\"\"\n",
    "        model.train()\n",
    "        logging.info('SET model mode to train!')\n",
    "        batch_iter = 0\n",
    "        tbar = tqdm(train_loader)\n",
    "        for batch_img1, batch_img2, labels in tbar:\n",
    "            tbar.set_description(\"epoch {} info \".format(epoch) + str(batch_iter) + \" - \" + str(batch_iter+opt.batch_size))\n",
    "            batch_iter = batch_iter+opt.batch_size\n",
    "            total_step += 1\n",
    "            # Set variables for training\n",
    "            batch_img1 = batch_img1.float().to(dev)\n",
    "            batch_img2 = batch_img2.float().to(dev)\n",
    "            labels = labels.long().to(dev)\n",
    "\n",
    "            # Zero the gradient\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Get model predictions, calculate loss, backprop\n",
    "            cd_preds = model(batch_img1, batch_img2)\n",
    "\n",
    "            cd_loss = criterion(cd_preds, labels)\n",
    "            loss = cd_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            cd_preds = cd_preds[-1]\n",
    "            _, cd_preds = torch.max(cd_preds, 1)\n",
    "\n",
    "            # Calculate and log other batch metrics\n",
    "            cd_corrects = (100 *\n",
    "                           (cd_preds.squeeze().byte() == labels.squeeze().byte()).sum() /\n",
    "                           (labels.size()[0] * (opt.patch_size**2)))\n",
    "\n",
    "            cd_train_report = prfs(labels.data.cpu().numpy().flatten(),\n",
    "                                   cd_preds.data.cpu().numpy().flatten(),\n",
    "                                   average='binary',\n",
    "                                   zero_division=0,\n",
    "                                   pos_label=1)\n",
    "\n",
    "            train_metrics = set_metrics(train_metrics,\n",
    "                                        cd_loss,\n",
    "                                        cd_corrects,\n",
    "                                        cd_train_report,\n",
    "                                        scheduler.get_last_lr())\n",
    "\n",
    "            # log the batch mean metrics\n",
    "            mean_train_metrics = get_mean_metrics(train_metrics)\n",
    "\n",
    "            for k, v in mean_train_metrics.items():\n",
    "                writer.add_scalars(str(k), {'train': v}, total_step)\n",
    "\n",
    "            # clear batch variables from memory\n",
    "            del batch_img1, batch_img2, labels\n",
    "\n",
    "        scheduler.step()\n",
    "        logging.info(\"EPOCH {} TRAIN METRICS\".format(epoch) + str(mean_train_metrics))\n",
    "\n",
    "        \"\"\"\n",
    "        Begin Validation\n",
    "        \"\"\"\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_img1, batch_img2, labels in val_loader:\n",
    "                # Set variables for training\n",
    "                batch_img1 = batch_img1.float().to(dev)\n",
    "                batch_img2 = batch_img2.float().to(dev)\n",
    "                labels = labels.long().to(dev)\n",
    "\n",
    "                # Get predictions and calculate loss\n",
    "                cd_preds = model(batch_img1, batch_img2)\n",
    "\n",
    "                cd_loss = criterion(cd_preds, labels)\n",
    "\n",
    "                cd_preds = cd_preds[-1]\n",
    "                _, cd_preds = torch.max(cd_preds, 1)\n",
    "\n",
    "                # Calculate and log other batch metrics\n",
    "                cd_corrects = (100 *\n",
    "                               (cd_preds.squeeze().byte() == labels.squeeze().byte()).sum() /\n",
    "                               (labels.size()[0] * (opt.patch_size**2)))\n",
    "\n",
    "                cd_val_report = prfs(labels.data.cpu().numpy().flatten(),\n",
    "                                     cd_preds.data.cpu().numpy().flatten(),\n",
    "                                     average='binary',\n",
    "                                     zero_division=0,\n",
    "                                     pos_label=1)\n",
    "\n",
    "                val_metrics = set_metrics(val_metrics,\n",
    "                                          cd_loss,\n",
    "                                          cd_corrects,\n",
    "                                          cd_val_report,\n",
    "                                          scheduler.get_last_lr())\n",
    "\n",
    "                # log the batch mean metrics\n",
    "                mean_val_metrics = get_mean_metrics(val_metrics)\n",
    "\n",
    "                for k, v in mean_train_metrics.items():\n",
    "                    writer.add_scalars(str(k), {'val': v}, total_step)\n",
    "\n",
    "                # clear batch variables from memory\n",
    "                del batch_img1, batch_img2, labels\n",
    "\n",
    "            logging.info(\"EPOCH {} VALIDATION METRICS\".format(epoch)+str(mean_val_metrics))\n",
    "\n",
    "            \"\"\"\n",
    "            Store the weights of good epochs based on validation results\n",
    "            \"\"\"\n",
    "            if ((mean_val_metrics['cd_precisions'] > best_metrics['cd_precisions'])\n",
    "                    or\n",
    "                    (mean_val_metrics['cd_recalls'] > best_metrics['cd_recalls'])\n",
    "                    or\n",
    "                    (mean_val_metrics['cd_f1scores'] > best_metrics['cd_f1scores'])):\n",
    "\n",
    "                # Insert training and epoch information to metadata dictionary\n",
    "                logging.info('updata the model')\n",
    "                metadata['validation_metrics'] = mean_val_metrics\n",
    "\n",
    "                # Save model and log\n",
    "                if not os.path.exists('./tmp'):\n",
    "                    os.mkdir('./tmp')\n",
    "                with open('./tmp/metadata_epoch_' + str(epoch) + '.json', 'w') as fout:\n",
    "                    json.dump(metadata, fout)\n",
    "\n",
    "                torch.save(model, './tmp/checkpoint_epoch_'+str(epoch)+'.pt')\n",
    "\n",
    "                # comet.log_asset(upload_metadata_file_path)\n",
    "                best_metrics = mean_val_metrics\n",
    "\n",
    "\n",
    "            print('An epoch finished.')\n",
    "    writer.close()  # close tensor board\n",
    "    print('Done!')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BCODE",
   "language": "python",
   "name": "bcode"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
